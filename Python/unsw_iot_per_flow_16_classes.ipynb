{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoT device list for labeling\n",
    "IoT_Device_List = pd.read_csv(\"iot_device_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 16 classes under consideration\n",
    "classes = [\"Withings Smart Baby Monitor\",\"Withings Aura smart sleep sensor\",\"Dropcam\",\n",
    "           \"TP-Link Day Night Cloud camera\",\"Samsung SmartCam\",\"Netatmo weather station\",\"Netatmo Welcome\",\n",
    "          \"Amazon Echo\", \"Laptop\",\"NEST Protect smoke alarm\",\"Insteon Camera\",\"Belkin Wemo switch\",\n",
    "           \"Belkin wemo motion sensor\", \"Light Bulbs LiFX Smart Bulb\", \"Triby Speaker\", \"Smart Things\"]\n",
    "classes_df = pd.DataFrame(classes, columns=['class'])\n",
    "IoT_Device_List_16 = IoT_Device_List[IoT_Device_List[\"List of Devices\"].isin(classes)]\n",
    "IoT_Device_List_16 = IoT_Device_List_16.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Run grid search on RF hyperparameters - maximum tree depth and number of estimators \"\"\"\n",
    "def RF_evaluation(X_train, y_train, X_test, y_test, threshold, mode, depth_range, tree_range, labels, target_names):\n",
    "    scores_iot = []\n",
    "    for max_depth in depth_range:\n",
    "        for num_trees in tree_range:\n",
    "            RF = RandomForestClassifier(max_depth = max_depth, n_estimators = num_trees, random_state=42, bootstrap=False)\n",
    "            RF = RF.fit(X_train, y_train)\n",
    "            y_pred_rf = RF.predict(X_test)\n",
    "            F1score = 100*f1_score(y_test, y_pred_rf, average=mode)            \n",
    "            class_report = classification_report(y_test, y_pred_rf, labels = labels, target_names=target_names, output_dict = True)\n",
    "            if F1score > 70:\n",
    "                print('\\n ##')\n",
    "                print(\"F1-score:\", F1score)\n",
    "    return class_report, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to Fit model based on optimal values of depth and number of estimators and use it\n",
    "to compute feature importance for all the features according to MDI\n",
    "\"\"\"\n",
    "def get_feature_importance(evaluation, X_train, y_train):\n",
    "    rf_opt = RandomForestClassifier(max_depth = evaluation[1], n_estimators = evaluation[2], random_state=42)\n",
    "    rf_opt.fit(X_train, y_train)\n",
    "    Feature_importance = pd.DataFrame(rf_opt.feature_importances_)\n",
    "    Feature_importance.index = X_train.columns\n",
    "    Feature_importance = Feature_importance.sort_values(by=list(Feature_importance.columns),axis=0,ascending=False)\n",
    "    return Feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to Fit model based on optimal values of depth and number of estimators and feature importance\n",
    "to find the fewest possible features to exceed the previously attained score with all selected features\n",
    "\"\"\"\n",
    "def get_fewest_features(evaluation, importance, X_train, y_train, X_test, y_test, f1_threshold, mode):    \n",
    "    sorted_feature_names = importance.index\n",
    "    fewest_tuple = []\n",
    "    for f in range(1,len(sorted_feature_names)+1):\n",
    "        rf_try = RandomForestClassifier(max_depth=evaluation[1], n_estimators = evaluation[2], \n",
    "                                        random_state=42)\n",
    "        rf_try.fit(X_train[sorted_feature_names[0:f]], y_train)\n",
    "        y_pred = rf_try.predict(X_test[sorted_feature_names[0:f]])\n",
    "        score = f1_score(y_test, y_pred, average=mode)\n",
    "        tuple_feat = [f, score,sorted_feature_names[0:f]]\n",
    "        print(tuple_feat)\n",
    "        if(score >= f1_threshold):\n",
    "            return tuple_feat\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function to extract bits n to m from a bitstring \"\"\"\n",
    "def extractKBits(num, start_bit, end_bit):\n",
    "    # convert number into binary first\n",
    "    binary = bin(int(num))\n",
    "    # remove first two characters and fill to 48 bits\n",
    "    binary = binary[2:].zfill(48)\n",
    "    #extract required bits\n",
    "    num_32bits = binary[16:48]\n",
    "    num_bin = num_32bits[start_bit:end_bit]\n",
    "    num_bin = \"0b\" + num_bin\n",
    "    num_dec = int(num_bin,2)\n",
    "    return num_dec\n",
    "    \n",
    "# get new train and test data with n to m bits selected    \n",
    "def compress_feature(X_train, X_test, n, m,  feature):\n",
    "    X_train_func, X_test_func = X_train.copy(), X_test.copy()\n",
    "    X_train_func[feature] = [extractKBits(x, n, n + m) for x in X_train_func[feature]]\n",
    "    X_test_func[feature] = [extractKBits(x, n, n + m) for x in X_test_func[feature]]\n",
    "    \n",
    "    return X_train_func, X_test_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function to fit the final models which we will translate to P4 \"\"\"\n",
    "def fit_final_model(few, evaluation, X_train, y_train):    \n",
    "    rf_final = RandomForestClassifier(max_depth= evaluation[1], \\\n",
    "        n_estimators = evaluation[2], random_state=42, bootstrap = False)\n",
    "    rf_final.fit(X_train[few], y_train)\n",
    "    return rf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save trained model for onward processing \"\"\"\n",
    "def save_model(RF, filename):\n",
    "    pickle.dump(RF, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Label Flows based on MAC address information in the IoT device list file \"\"\"\n",
    "def label_flows(IoT_Train, IoT_Device_List):\n",
    "    IoT_Train['Label_New'] = len(IoT_Train)*[0]\n",
    "    for i in range(len(IoT_Device_List)):\n",
    "        IoT_Train['Label_New'] = np.where((IoT_Train['Src MAC']==IoT_Device_List[\"MAC ADDRESS\"][i]), \n",
    "                                          IoT_Device_List[\"List of Devices\"][i], IoT_Train['Label_New'])\n",
    "\n",
    "    for i in range(len(IoT_Device_List)):\n",
    "        IoT_Train['Label_New'] = np.where((IoT_Train['Dst MAC']==IoT_Device_List[\"MAC ADDRESS\"][i]) & \n",
    "                                       (IoT_Train['Src MAC']==\"14:cc:20:51:33:ea\"), \n",
    "                                      IoT_Device_List[\"List of Devices\"][i], IoT_Train['Label_New'])\n",
    "\n",
    "    IoT_Train = IoT_Train[IoT_Train['Label_New']!=\"TPLink Router Bridge LAN (Gateway)\"]\n",
    "    IoT_Train = IoT_Train[IoT_Train['Label_New']!=\"0\"]\n",
    "    IoT_Train = IoT_Train[IoT_Train['Label_New']!=\"Nest Dropcam\"]\n",
    "    IoT_Train = IoT_Train[IoT_Train['Label_New']!=\"MacBook/Iphone\"]\n",
    "\n",
    "    return IoT_Train\n",
    "\n",
    "\"\"\" Extract features from train data\"\"\"\n",
    "def prepare_train(IoT):\n",
    "    X_train = IoT.drop([\"Flow ID\",'Label', 'Src MAC', 'Dst MAC', 'Protocol', 'Packet Count', \n",
    "                        'Label_New','Flow IAT Mean','Packet Length Mean'], axis=1)\n",
    "    y_train = IoT['Label_New'].replace(classes, range(len(IoT[\"Label_New\"].unique())))\n",
    "    return X_train, y_train\n",
    "\n",
    "\"\"\" Extract features from test data\"\"\"\n",
    "def prepare_test(Test, Train):\n",
    "    X_test = Test.drop([\"Flow ID\", 'Src MAC', 'Dst MAC', 'Protocol', 'Packet Count', 'Label_New', \n",
    "                        'Flow IAT Mean','Packet Length Mean'], axis=1)\n",
    "    y_test = Test['Label_New'].replace(classes, range(len(Train[\"Label_New\"].unique())))\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get combinations of models for different number of trees, maximum tree depth and number of features\"\"\"\n",
    "def analyze_models_features(depths, n_trees, X_train, y_train, X_test, y_test, max_feats):\n",
    "    for depth in depths:\n",
    "        for n_tree in n_trees:\n",
    "            print(\"Depth, Tree:\", depth, n_tree)\n",
    "            importance = get_feature_importance([None, depth, n_tree], X_train, y_train)\n",
    "            print(importance)\n",
    "            get_fewest_features([None, depth, n_tree], importance[0:max_feats], X_train, y_train, X_test, y_test, 99, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get names and indices of classes present in the test data \"\"\"\n",
    "def get_test_labels(IoT_Test):\n",
    "    array_of_indices = []\n",
    "    unique_labels = IoT_Test[\"Label_New\"].unique()\n",
    "    for lab in unique_labels:\n",
    "        index = classes_df[classes_df['class'] == lab].index.values[0]\n",
    "        array_of_indices.append(index)\n",
    "    return unique_labels, array_of_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Find the best number of bits and their positions, that yield similar or better model performance.\n",
    "As range matches in hardware cannot support all sizes of variables, we propose this technique to \n",
    "extract just n bits from the features with longer bit sizes and use just those n bits in model training.\n",
    "In the switch as well, only the n bits that were used in training will be extracted for that feature and \n",
    "used for in-switch inference.\n",
    "\"\"\"\n",
    "def find_time_shifts(X_train, X_test, y_train, y_test, features, test_ind, test_lab, d_range, t_range):\n",
    "    for m1 in range(1, 16):\n",
    "        for m2 in range(1, 16):\n",
    "            X_train1, X_test1 = compress_feature(X_train, X_test, 0, m1, 'Flow Duration')\n",
    "            X_train2, X_test2 = compress_feature(X_train1, X_test1, 0, m2, 'Flow IAT Max')\n",
    "            c_report, RF = RF_evaluation(X_train2[features], y_train, X_test2[features], y_test, \n",
    "                                     90, 'macro', d_range, t_range, test_ind, test_lab)\n",
    "            macro_f1 = 100*c_report['macro avg']['f1-score']\n",
    "            if macro_f1 > 92:\n",
    "                print(\"Compression applied to 'Flow Duration': 32 -> \", 32 - m1)\n",
    "                print(\"Compression applied to 'Flow IAT Max': 32 -> \", 32 - m2)\n",
    "                print('Macro F1-score (from c. rep.): ', macro_f1)\n",
    "\n",
    "\"\"\" Once the bit positions are known, we can then regenerate the train and test data features with the modified features\"\"\"\n",
    "def get_final_compression(X_train, X_test, y_train, y_test, features, test_ind, test_lab, d_range, t_range, m1, m2):\n",
    "\n",
    "    X_train1, X_test1 = compress_feature(X_train, X_test, 0, m1, 'Flow Duration')\n",
    "    X_train2, X_test2 = compress_feature(X_train1, X_test1, 0, m2, 'Flow IAT Max')\n",
    "    c_report, final_rf = RF_evaluation(X_train2[features], y_train, X_test2[features], y_test, 90, 'macro', d_range, t_range, test_ind, test_lab)\n",
    "    macro_f1 = 100*c_report['macro avg']['f1-score']\n",
    "    \n",
    "    print(\"Compression applied to 'Flow Duration': 32 -> \", 32 - m1)\n",
    "    print(\"Compression applied to 'Flow IAT Max': 32 -> \", 32 - m2)\n",
    "    print('Macro F1-score (from c. rep.): ', macro_f1)\n",
    "    \n",
    "    return X_train2[features], X_test2[features], final_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Obtains final trained model and performance statistics based on selected value of max_leaf_nodes\"\"\"\n",
    "def prune_model(X_train, y_train, X_test, y_test, depth, trees, max_leaves, indices, labels):\n",
    "    MaxTen = 0 # MaxTen is max number of bits supported for a ternary match key in hardware. Actual value is confidential \n",
    "    model = RandomForestClassifier(max_depth = depth, n_estimators = trees, max_leaf_nodes=max_leaves, random_state=42, bootstrap=False)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred_rf = model.predict(X_test)\n",
    "    F1score = 100*f1_score(y_test, y_pred_rf, average='macro')\n",
    "    c_report = classification_report(y_test, y_pred_rf, labels = indices, target_names=labels, output_dict = True)\n",
    "    macro_f1 = 100*c_report['macro avg']['f1-score']\n",
    "    \n",
    "    if macro_f1 > 80:    \n",
    "        print(\"####\")\n",
    "        print(\"Macro F1-score:\", F1score)\n",
    "        print('Macro F1-score (from c. rep.): ', macro_f1)\n",
    "        \n",
    "        for num in range(len(model.estimators_)):\n",
    "            nbitsp4 = model.estimators_[num].tree_.node_count - model.estimators_[num].tree_.n_leaves\n",
    "            print(\"Number of bits in P4: \", nbitsp4)\n",
    "            if nbitsp4 > MaxTen:\n",
    "                print(\"############### ERRROR ###############\")\n",
    "                \n",
    "    return model, c_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection, Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and label training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labelled excel files\n",
    "IoT_Train_csv = pd.read_csv(\"rf3_train.csv\")\n",
    "\n",
    "# Label the flows, convert time features to nanoseconds\n",
    "IoT_Train = label_flows(IoT_Train_csv, IoT_Device_List_16)\n",
    "X_train, y_train = prepare_train(IoT_Train)\n",
    "X_train['Flow IAT Min'] = X_train['Flow IAT Min']*1000\n",
    "X_train['Flow IAT Max'] = X_train['Flow IAT Max']*1000\n",
    "X_train['Flow Duration'] = X_train['Flow Duration']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See number of samples per device class\n",
    "IoT_Train.groupby(\"Label_New\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and label test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "IoT_Test_csv = pd.read_csv(\"rf3_test.csv\")\n",
    "\n",
    "# Label test data\n",
    "IoT_Test = label_flows(IoT_Test_csv, IoT_Device_List_16)\n",
    "\n",
    "# Separate features from the dependent variable\n",
    "X_test, y_test = prepare_test(IoT_Test, IoT_Train)\n",
    "\n",
    "# Get names and indices of represented classes\n",
    "test_labels, test_indices = get_test_labels(IoT_Test)\n",
    "\n",
    "# See if any missing classes\n",
    "set(classes) - set(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# analyze_models_features(set_of_max_tree_depths, set_of_number_of_trees, X_train, y_train, X_test[X_train.columns], y_test, max_num_of_features)\n",
    "analyze_models_features([5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10], X_train, y_train, X_test[X_train.columns], y_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model is (depth = 10, n_trees = 3) with 7 features - 94.38 %\n",
    "Selected_Features = ['Packet Length Total', 'Flow Duration', 'Max Packet Length','Source Port', 'Min Packet Length', 'Destination Port', 'Flow IAT Max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find optimal bits for time-based features e.g Flow Duration and Flow IAT Max\n",
    "find_time_shifts(X_train, X_test, y_train, y_test, Selected_Features, test_indices, test_labels, [10], [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best models are those with first 3 MSBs of Flow Duration and first 5 MSBs of Flow IAT Max\n",
    "\"\"\"\n",
    "Accuracy: 98.47165532879819\n",
    "F1-score: 93.91843072591722\n",
    "Compression applied to 'Flow Duration': 32 ->  29\n",
    "Compression applied to 'Flow IAT Max': 32 ->  27\n",
    "Macro F1-score (from c. rep.):  93.91843072591722\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######\n",
      "Accuracy: 98.47165532879819\n",
      "F1-score: 93.91843072591722\n",
      "Compression applied to 'Flow Duration': 32 ->  29\n",
      "Compression applied to 'Flow IAT Max': 32 ->  27\n",
      "Macro F1-score (from c. rep.):  93.91843072591722\n"
     ]
    }
   ],
   "source": [
    "# Use selected bits to obtain compressed X_train, y_train and final model\n",
    "X_train_comp_29_27, X_test_comp_29_27, rf_final_comp_29_27 = get_final_compression(X_train, X_test, y_train, y_test, \n",
    "                                                                                   Selected_Features,test_indices, \n",
    "                                                                                   test_labels, [10], [3], \n",
    "                                                                                   3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bits in P4:  437\n",
      "Number of bits in P4:  523\n",
      "Number of bits in P4:  474\n"
     ]
    }
   ],
   "source": [
    "# Check if Pruning is required for nbits to fit hardware constraints\n",
    "for num in range(len(rf_final_comp_29_27.estimators_)):\n",
    "    nbitsp4 = rf_final_comp_29_27.estimators_[num].tree_.node_count - rf_final_comp_29_27.estimators_[num].tree_.n_leaves\n",
    "    print(\"Number of bits in P4: \", nbitsp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find optimal value of max_leaf_nodes that preserves accuracy reasonably \n",
    "# but cuts down number of bits required to encode tree\n",
    "for leaf in range(200, 512, 10):\n",
    "    print(\"leaves:\", leaf)\n",
    "    prune_model(X_train_comp_29_27, y_train, X_test_comp_29_27, y_test, 10, 3, leaf, test_indices, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "Accuracy: 98.71655328798185\n",
      "Macro F1-score: 90.67521742444109\n",
      "Macro F1-score (from c. rep.):  90.67521742444109\n",
      "Number of bits in P4:  349\n",
      "Number of bits in P4:  349\n",
      "Number of bits in P4:  349\n"
     ]
    }
   ],
   "source": [
    "# Use selected value of 350 as max_leaf_nodes to get final model and performance in classification report\n",
    "final_10_3_29_27_model, cl_report_29_27_full = prune_model(X_train_comp_29_27, y_train, X_test_comp_29_27, \n",
    "                                          y_test, 10, 3, 350, test_indices, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for onward conversion into M/A entries\n",
    "save_model(final_10_3_29_27_model, \"unsw_per_flow_saved_model_16_classes.sav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
